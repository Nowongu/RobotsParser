<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net6.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <PackageId>Nick.RobotsParser</PackageId>
    <Version>2.0.2</Version>
    <Authors>Nicholas Bergesen</Authors>
    <Company>Nicholas Bergesen</Company>
    <PackageReleaseNotes>
	- Improve sitemap parsing robustness.
	- Ignore sitemap parsing errors.
    </PackageReleaseNotes>
    <PackageTags>robots,parse robots,web crawling,robots.txt,web scraping,spider,sitemap,sitemap parse</PackageTags>
    <Description>
      This client library enables working with Robots.txt.
      Key Features:
        - Parse robots.txt into Typed object.
        - Lookup Allowed/Disallowed/Crawldelay based on User-Agent.
        - Traverse sitemap in robots.txt for urls.

      For More info see: https://github.com/nicholasbergesen/robotsSharp/master/README.md
    </Description>
  </PropertyGroup>
  
</Project>
